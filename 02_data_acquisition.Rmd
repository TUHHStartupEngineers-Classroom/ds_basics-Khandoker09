---
title: "02 Data Acqusition"
date: "2021-04"
output:
  html_document:
    toc: true
    toc_float: true
    df_print: paged
    collapsed: false
    number_sections: true
    toc_depth: 3
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message=FALSE,warning=FALSE, cache=TRUE)
```

# Challenge 

Get some data via an API. There are millions of providers, that offer API access for free and have good documentation about how to query their service. You just have to google them. You can use whatever service you want. For example, you can get data about your listening history (spotify), get data about flights (skyscanner) or just check the weather forecast. Print the data in a readable format, e.g. a table if you want, you could also plot it.

```{r}
# Import dependencies 
library(httr)
library(glue)
library(tibble)
library(jsonlite)
library(tidyverse)
library(purrr)
library(stringr)
library('rvest')
library(xml2)
 
#challenge 1
# load data from api using website 

webpage_url <- "https://apify.com/covid-19"
webpage <- xml2::read_html(webpage_url)
data_accuisition1 <- rvest::html_table(webpage)[[1]] %>% 
  tibble::as_tibble(.name_repair = "unique") # repair the repeated columns
data_accuisition1 %>% dplyr::glimpse(45)

# save data in readable format < csv and rds 
data_accuisition1 

#write.csv(x=data_accuisition1, file="F:\\1edutuhh\\business data\\git\\ds_basics-Khandoker09\\covid_data.csv")
#write_rds(data_accuisition1, "F:\\1edutuhh\\business data\\git\\ds_basics-Khandoker09\\data_accuisition1.rds")

```

Scrape one of the competitor websites of canyon (either https://www.rosebikes.de/ or https://www.radon-bikes.de) and create a small database. The database should contain the model names and prices for at least one category. Use the selectorgadget to get a good understanding of the website structure, it is really helpful. After scraping your data, convert it to a readable format. Prices should be in a numeric format without any other letters or symbols. Also check if the prices are reasonable.

```{r}
# Import dependencies 

library(tidyverse) 
library(rvest)     
library(xopen)     
library(jsonlite)  
library(glue)      
library(stringi)   

# load data from rose bike

url_home          <- "https://www.rosebikes.de/fahrr%C3%A4der/e-bike"

# Read in the HTML for the entire webpage

html_home         <- read_html(url_home)

# Web scraping the bike models 
bike_model <- html_home %>% 
  
  html_nodes(css = ".catalog-category-bikes__title-text") %>% 
  html_text() %>%
  
  str_remove_all("\n") 

bike_model

# scraping bike prices

bike_price <- html_home %>%
  
  html_nodes(css = ".catalog-category-bikes__price-title") %>%
  html_text() %>%
  
  str_remove_all("\\.") %>%
  stringr::str_replace_all(pattern = "\nab ", replacement = "") %>%
  stringr::str_replace_all(pattern = "\n", replacement = "") 

bike_price

# merging the two tables into one

data_accuisition2 <- tibble(bike_model, bike_price)
data_accuisition2 <- data_accuisition2 %>% mutate(bike_price = as.character(gsub("â‚¬", "", bike_price)))
d<-data_accuisition2
d$bike_price <- as.character(gsub("ab","",d$bike_price))
d$bike_price <- as.character(gsub(",","",d$bike_price))
data_accuisition2 <- d

# save the data into readable format like csv or rds 
data_accuisition2 

#write_rds(data_accuisition2, "F:\\1edutuhh\\business data\\git\\ds_basics-Khandoker09\\data_accuisition2.rds")
#write.csv(x=data_accuisition2, file="F:\\1edutuhh\\business data\\git\\ds_basics-Khandoker09\\data_accuisition2.csv")




```